
# README: 使用 Python对伪标签进行半监督学习

---

## 背景知识

### 什么是伪标签？
伪标签是一种**让模型自己生成标签**的策略，通常用于无监督或弱监督的机器学习任务。因为在无监督的场景中，我们没有真实的标签数据，所以伪标签的想法是让模型先做出一些初步预测，然后从这些预测中选择出它“自信”部分的结果，作为临时的标签来指导进一步学习

**适用场景**：
- 标注数据不足时
- 有大量未标注数据可用时

### 伪标签的具体工作原理
1. **模型初步训练**：先用无标签的数据训练一个初步的模型。这时，模型可以做出一些预测，但由于没有标签数据，它的预测准确性可能不高
  
2. **生成伪标签**：在初步训练的基础上，模型会对数据做出预测。然后，模型从这些预测中选择它认为较为准确的部分，作为“伪标签”
   - 例如，模型预测某些区域是目标物体，而在这些区域上它的预测结果非常稳定或一致，就会认为这些预测是可靠的，并将这些区域标记为伪标签

3. **进一步学习**：利用这些伪标签，模型继续学习和改进。伪标签帮助模型找到学习方向，相当于提供了一个“自我引导”的参考。模型逐步修正自己，从而提升分割的准确性

### 效果如何？
伪标签的方法有效地提升了无监督学习的表现，尤其在早期没有标签的情况下。但伪标签的效果依赖于模型的初始预测质量。假如模型的初始预测不够准确，那么生成的伪标签也可能带有错误，从而影响后续学习效果。所以伪标签的质量是决定模型最终分割效果的关键

---
## 目的

本项目旨在帮助大家了解和学会使用伪标签Pseudo-Labeling技术。伪标签是一种半监督学习的方法，用于从未标注的数据中挖掘潜在信息，提升模型性能

---

## 示例

### 示例代码功能

代码的功能分为以下几个阶段：
1. **生成伪标签**：
   - 使用训练好的初始模型对未标注数据进行预测
   - 从预测结果中选取高置信度的样本生成伪标签
2. **筛选伪标签**：
   - 设置置信度阈值，过滤掉低置信度的预测，减少伪标签中的噪声
3. **利用伪标签训练**：
   - 将筛选后的伪标签样本加入训练集，继续优化模型

---

## 配置

### 环境依赖

运行代码需要以下依赖：
- Python 3.7+
- PyTorch 1.10+
- numpy
- tqdm

可以使用以下命令安装依赖：
```bash
pip install torch numpy tqdm
```

---

### 使用步骤

1. **准备数据**：
   - 确保你有一个标注数据集（用于初始模型训练）和一个未标注数据集（用于生成伪标签）

2. **运行代码**：
   - 在`pseudo_labeling.py`中配置你的数据路径和模型参数
   - 执行以下命令生成伪标签并重新训练模型：
     ```bash
     python pseudo_labeling.py
     ```

3. **查看结果**：
   - 模型的训练日志会输出在控制台，最终模型保存在`outputs/`目录下

---

### 说明和解读

#### 核心代码片段

1. **伪标签生成**
   ```python
   outputs = model(inputs)   #使用模型预测
   probs = F.softmax(outputs, dim=1)  #转换为概率分布
   max_probs, pseudo_label = torch.max(probs, dim=1)  #最大概率及伪标签
   ```

   - **功能**：通过 `softmax` 得到类别概率分布，选择概率最大的类别作为伪标签

2. **高置信度筛选**
   ```python
   mask = max_probs > threshold  #筛选置信度高于阈值的样本
   selected_samples = inputs[mask]
   pseudo_labels = pseudo_label[mask]
   ```

   - **功能**：只保留模型对其预测有足够置信的样本，避免伪标签误差传播

3. **训练模型**
   ```python
   outputs = model(selected_samples)  #用高置信度伪标签样本训练模型
   loss = criterion(outputs, pseudo_labels)
   loss.backward()
   optimizer.step()
   ```

   - **功能**：使用伪标签数据更新模型参数

---

## 场景举例

- **场景**：你有一个包含10,000张图片的数据集，其中只有2,000张有标签（标注为猫或狗），剩下8,000张未标注
- **步骤**：
  1. 用标注数据训练初始模型
  2. 用模型预测未标注数据的标签（伪标签）
  3. 只选择预测结果可信度高于90%的样本（例如“这张图片99%是猫”）
  4. 用这些高置信度的伪标签数据继续训练模型

---

## 需要注意

1. **置信度阈值的选择**：
   - 如果阈值过高，可能筛选的伪标签样本过少，无法充分利用数据
   - 如果阈值过低，可能引入过多错误伪标签，影响模型性能

2. **伪标签的迭代更新**：
   - 在训练过程中，可以逐步更新伪标签，使模型利用更多未标注数据

3. **错误传播风险**：
   - 在伪标签中混入错误样本可能导致模型性能下降。可结合软伪标签或多模型协作减少风险

---

## 总结


| **场景**               | **现状**                                                                 | **未来改进方向**                                                                                     |
|------------------------|------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------|
| **伪标签质量**          | 依赖单一模型生成，可能包含大量错误                                        | 引入多模型协作、软伪标签与抗噪机制                                                                   |
| **低置信度样本利用**     | 仅利用高置信度样本，丢弃大部分低置信度数据                                | 使用一致性正则化和自监督方法挖掘低置信度样本价值                                                     |
| **抗噪与动态性**         | 伪标签更新固定，错误易传播                                              | 动态伪标签更新与抗噪训练方法                                                                         |
| **生成能力与数据增强**    | 依赖判别模型，缺乏生成能力                                              | 融合生成对抗网络（GAN）和扩散模型，扩展伪标签生成能力                                               |
| **领域适应与跨模态**     | 在单一模态或单领域中效果较好                                            | 推广到跨领域迁移和多模态学习                                                                         |
| **理论研究**            | 以实验驱动为主，缺乏数学理论支持                                        | 构建伪标签影响泛化性能和优化过程的理论框架                                                           |

---

## 学习资源

- [论文：Pseudo-Labeling and Self-training](https://arxiv.org/abs/1905.13736)
- [PyTorch官方教程](https://pytorch.org/tutorials/)

---

欢迎反馈问题或建议！ 😊
